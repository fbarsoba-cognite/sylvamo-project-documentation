# Contextualization Quality Baseline Results (`sylvamo-dev`)

## Dashboard Reference

- Context Quality Dashboard (Dev): https://sylvamo.fusion.cognite.com/sylvamo-dev/streamlit-apps/applications/context_quality_dashboard?cluster=az-eastus-1.cognitedata.com&workspace=industrial-tools

**Run type:** API-driven batch mode (UI workaround)  
**Batch plan:** 10 batches x 5,000 (target 50,000)  
**Total runtime:** ~196s for batch+aggregation  
**Computed at (UTC):** 2026-02-20T20:01:12Z

---

## 1) Batch Configuration (UI-equivalent)

- **Batch size:** 50,000 total, executed as 5,000 increments via API
- **Number of batches:** 10
- **Why API:** UI minimum (50,000) was causing graph query timeout; API increments avoided this

**Status:** **OK**

---

## 2) Batch Execution (UI-equivalent)

- **Submitted batches:** 10/10
- **Completed batches:** 10/10
- **Failed batches:** 0
- **Aggregation:** Completed

**Status:** **OK**

---

## 3) Metrics Info (UI-equivalent)

- **Execution time (final metrics file):** 1.91s (aggregation write step)
- **Batch mode:** true
- **Batches merged:** 10

**Status:** **OK**

---

## 4) Instance Counts (UI-equivalent)

- **Assets:** 45,953 (unique 45,953; duplicates 0)
- **Time Series:** 3,764 (unique 3,764; duplicates 0)
- **Equipment:** 0
- **Notifications:** 0
- **Maintenance Orders:** 0

**Status:**
- Assets/TS counts: **OK**
- Equipment/Maintenance counts: **NOT OK** (no equipment/maintenance data represented in this baseline run)

---

## 5) Processing Status (UI-equivalent)

- Data pipeline execution completed and metrics persisted to CDF file.

**Status:** **OK**

---

## 6) Dashboard Configuration Sections (as shown in UI)

## 6.1 Asset Hierarchy Dashboard

### What this category measures
- How structurally complete the asset tree is (parent-child relationships, roots, orphans).
- Whether the hierarchy shape is operationally usable (depth and breadth distribution).

### How to improve
- Eliminate orphan assets by enforcing parent assignment rules in ingestion/transformation logic.
- Validate hierarchy mapping rules for new assets before deployment (especially top-level placement).
- Review high-fanout parents and split overloaded branches for better maintainability.

### Key results
- **Hierarchy completion rate:** 100.0%
- **Orphan rate:** 0.0% (orphans: 0)
- **Root assets:** 2
- **Average depth:** 5.93
- **Max depth:** 7
- **Average children:** 5.18
- **Max children:** 164

### Assessment
- **What is OK**
  - Structural completeness is strong (100% completion, zero orphans).
  - Depth profile looks mature (deep but coherent hierarchy).
- **What is NOT OK / watchlist**
  - Very high max breadth (164 children) suggests some high-fanout parent nodes worth reviewing for modeling quality/readability.

**Section status:** **OK with watch items**

---

## 6.2 Time Series Dashboard

### What this category measures
- The percentage of time series correctly linked to assets/equipment.
- Metadata quality for units and freshness of telemetry.
- Whether time series coverage is broad enough across assets (monitoring coverage).

### How to improve
- Increase TS-to-asset coverage by expanding alias rules and contextualization mappings.
- Backfill unit metadata (`sourceUnit`/`targetUnit`) from source systems and enforce in pipelines.
- Prioritize unlinked TS (the current gap set) and run focused contextualization jobs.
- Add quality gates in transformations to flag missing unit and missing asset link.

### Key results
- **TS -> Asset association rate:** 94.9% (3,572 linked / 3,764 total)
- **TS without asset link:** 192
- **Asset monitoring coverage:** 0.04% (only 18 assets associated with TS)
- **Source unit completeness:** 61.56%
- **Target unit completeness:** 0.0%
- **Any unit completeness:** 61.56%
- **Data freshness:** 100.0%
- **Processing lag:** 15.66 hours

### Assessment
- **What is OK**
  - TS linkage quality is high at TS-record level (94.9% linked).
  - Freshness is strong (100% fresh).
- **What is NOT OK**
  - Asset-level TS coverage is very low (0.04%) -> weak monitoring coverage across asset population.
  - Unit metadata is incomplete, especially target units (0%).
- **Not evaluable yet**
  - Critical asset coverage and unit mapping rate are `None` (no critical set / mapping context in this run).

**Section status:** **PARTIALLY OK (major improvement needed on coverage + unit metadata)**

---

## 6.3 Equipment-Asset Dashboard

### What this category measures
- Whether equipment entities are populated and linked to the correct assets.
- Quality/completeness of critical equipment metadata (type, serial number, manufacturer).

### How to improve
- Ensure equipment ingestion is active and source tables are populated (`EQUI`, `EQUZ`, `ILOA`).
- Validate join path correctness (`EQUI -> EQUZ -> ILOA`) and current-assignment filters.
- Backfill serial/manufacturer/type fields and enforce not-null checks where feasible.
- Add data quality alerts for sudden drops in equipment counts or association rate.

### Key results
- **Total equipment:** 0
- **Association rate:** 0.0%
- **Asset coverage by equipment:** 0.0%
- **Serial/manufacturer completeness:** 0.0%

### Assessment
- **What is OK**
  - N/A (no equipment population in result set).
- **What is NOT OK**
  - Equipment contextualization is not represented in baseline metrics.
  - Any equipment KPI is currently non-actionable until equipment data is populated and linked.

**Section status:** **NOT OK (data gap)**

---

## 6.4 Maintenance Workflow Dashboard

### What this category measures
- Linkage quality across maintenance lifecycle entities (notification -> work order -> asset/equipment).
- Documentation completeness for failure mode/mechanism/cause and closure quality.

### How to improve
- Enable/validate maintenance source ingestion and ensure views are included in batch processing.
- Add relationship population logic for notification/order/asset/equipment references.
- Normalize failure taxonomy fields and enforce minimum documentation standards.

- **Maintenance metrics payload:** empty

**Section status:** **NOT OK / NOT AVAILABLE** (no maintenance data processed in this baseline)

---

## 6.5 File Annotation Dashboard

### What this category measures
- Annotation volume and quality on files/diagrams (status and confidence profile).
- Coverage of contextualized tags/assets/files in document corpus.

### How to improve
- Ensure annotation pipeline is active and output is written to expected CDM/edge views.
- Improve annotation precision by tuning extraction rules and confidence thresholds.
- Track low-confidence/rejected annotations and feed corrections back into rules/models.

- **File annotation metrics payload:** empty

**Section status:** **NOT OK / NOT AVAILABLE** (no annotation data processed in this baseline)

---

## 7) Overall Baseline Verdict

- **Strong:** Asset hierarchy structure and TS record-level linking quality.
- **Weak:** Asset monitoring coverage (TS spread across assets), equipment contextualization visibility, maintenance and annotation coverage.
- **Immediate focus areas:**
  1. Increase TS coverage across assets (not just TS link quality).
  2. Populate/validate equipment links so equipment KPIs become meaningful.
  3. Improve unit metadata completeness (especially target units).
  4. Bring maintenance and annotation datasets into baseline scope if expected.


## SVQS-235 Projection (Baseline -> Expected Uplift)

**Date:** 2026-02-20 UTC  
**Context:** Projection based on current Context Quality baseline and SVQS-235 implementation plan (deep PI-tag contextualization to specific instrument/deep asset nodes + web validation tool for the three Jira journeys).

### Baseline (from `contextualization_quality_metrics.json`)

- `timeseries_total`: **3,764**
- `ts_with_asset_link`: **3,572**
- `ts_to_asset_rate`: **94.9%**
- `ts_associated_assets`: **18**
- `assets_total`: **45,953**

### Projected Improvement

| KPI | Baseline | Projected After SVQS-235 | Expected Uplift |
|---|---:|---:|---:|
| PI tags linked to **specific** instrument/deep asset | Low (high concentration on parent assets) | 90-100% | **+70 to +95 percentage points** |
| `ts_associated_assets` (diversity of TS links across assets) | 18 | 500-3,500 | **+482 to +3,482** |
| `ts_to_asset_rate` (overall link completeness) | 94.9% | 97-100% | **+2.1 to +5.1 percentage points** |

### SVQS-235 Journey-Level Pass Targets

| User Journey (SVQS-235) | Baseline | Target |
|---|---|---|
| PI Tag -> specific asset/instrument | Inconsistent/non-deterministic | >=95% pass rate on sampled validation set |
| Asset/instrument -> linked PI tags | Limited at deep level | >=95% pass rate |
| P&ID annotation -> contextualized PI tags | Partial | >=85-95% pass rate (depends on annotation coverage) |

### Notes / Assumptions

1. The projected uplift emphasizes **linkage depth/precision**, not only broad linkage rate.
2. If implementation maps PI tags to per-tag virtual/deep nodes, uplift is expected near upper range.
3. If implementation maps to existing deep FLOCs only, uplift is expected in lower-to-mid range.
4. Journey pass rates are measured by the web validation tool introduced in SVQS-235 delivery.


## Combined Projection (SVQS-235 + SVQS-219 + SVQS-173)

This section factors in three Sprint 3 tickets together:
- `SVQS-235` Deep PI tag contextualization to deeper asset/instrument level
- `SVQS-219` PI tag category refinement/filtering for query precision
- `SVQS-173` PPV contextualization to paper machine assets for UC1 discoverability

### Combined Effect Summary

| Area | Baseline | After SVQS-235 only | After 235 + 219 + 173 |
|---|---|---|---|
| PI tag -> specific deep asset/instrument linkage | Low concentration on parent assets | 90-100% | 90-100% |
| Overall TS->Asset link completeness (`ts_to_asset_rate`) | 94.9% | 97-100% | 97-100% |
| Journey A pass rate (PI tag -> correct instrument, user-facing) | Inconsistent | ~95% | 97-99% |
| Journey B pass rate (asset/instrument -> relevant PI tags) | Limited at deep level | ~95% | 96-99% |
| UC1 business discoverability (asset -> quality context) | Partial | Moderate-High | High (TS + category + PPV) |

### Interpretation

- `SVQS-235` drives the structural uplift in contextualization depth.
- `SVQS-219` improves usability and precision by enabling category-level filtering for PI tags.
- `SVQS-173` adds business-context completeness by linking PPV records to assets, improving UC1 discoverability.

### Practical Outcome for Team Demo

When all three are implemented, the team should be able to show:
1. A PI tag resolves to a specific deep asset/instrument.
2. An asset view can be filtered to category-relevant PI tags.
3. From the same asset context, users can also find related PPV records.

This combination improves not only metric scores but also end-user confidence in contextualized search workflows.
